{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yH9F_hfUYulC",
        "outputId": "6a90c904-99d2-48ec-ca7c-07744283b711"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0+cu124\n",
            "False\n",
            "CUDA not available. Running on CPU.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print(\"CUDA not available. Running on CPU.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!unzip \"/content/drive/MyDrive/archive.zip\" -d /content/\n",
        "\n",
        "import os\n",
        "print(os.listdir('/content/COD10K-v3'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "O8o8ULKGb5ta",
        "outputId": "dce53298-5b5c-4b50-b93c-130b46f0c526"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3-189507576.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    135\u001b[0m   )\n\u001b[1;32m    136\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = '/content/COD10K-v3/Train'\n",
        "test_path = '/content/COD10K-v3/Test'"
      ],
      "metadata": {
        "id": "AlOfFbcYcret"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_subfolders(base_path):\n",
        "    return {\n",
        "        'image': f'{base_path}/Image',\n",
        "        'gt_object': f'{base_path}/GT_Object',\n",
        "        'gt_edge': f'{base_path}/GT_Edge',\n",
        "        'gt_instance': f'{base_path}/GT_Instance'\n",
        "    }\n",
        "\n",
        "train_folders = get_subfolders(train_path)\n",
        "test_folders = get_subfolders(test_path)"
      ],
      "metadata": {
        "id": "DmctIBIrcrhr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def count_files(folder_dict):\n",
        "    for key, folder in folder_dict.items():\n",
        "        print(f\"{key}: {len(os.listdir(folder))} files\")\n",
        "\n",
        "print(\"Train set:\")\n",
        "count_files(train_folders)\n",
        "print(\"\\nTest set:\")\n",
        "count_files(test_folders)"
      ],
      "metadata": {
        "id": "8DX5t0n5czjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "class COD10KDataset(Dataset):\n",
        "    def __init__(self, folders, transform=None, mask_transform=None):\n",
        "        self.image_paths = sorted(os.listdir(folders['image']))\n",
        "        self.image_dir = folders['image']\n",
        "        self.mask_dir = folders['gt_object']\n",
        "        self.transform = transform\n",
        "        self.mask_transform = mask_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_name = self.image_paths[idx]\n",
        "        img_path = os.path.join(self.image_dir, image_name)\n",
        "        mask_path = os.path.join(self.mask_dir, image_name.replace('.jpg', '.png'))\n",
        "\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        mask = Image.open(mask_path).convert('L')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.mask_transform:\n",
        "            mask = self.mask_transform(mask)\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "mask_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "full_dataset = COD10KDataset(train_folders, transform=transform, mask_transform=mask_transform)\n",
        "\n",
        "train_size = int(0.8 * len(full_dataset))\n",
        "val_size = len(full_dataset) - train_size\n",
        "\n",
        "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
        "\n",
        "batch_size = 48\n",
        "num_workers = 2\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
        "\n",
        "print(f\"Number of training samples: {len(train_dataset)}\")\n",
        "print(f\"Number of validation samples: {len(val_dataset)}\")\n",
        "print(f\"Number of training batches: {len(train_loader)}\")\n",
        "print(f\"Number of validation batches: {len(val_loader)}\")"
      ],
      "metadata": {
        "id": "UC7LfklTY6tI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_all_types(folders, indices):\n",
        "    n = len(indices)\n",
        "    fig, axes = plt.subplots(n, 4, figsize=(12, 5))\n",
        "    type_names = ['Image', 'GT_Object', 'GT_Edge', 'GT_Instance']\n",
        "    image_files = sorted(os.listdir(folders['image']))\n",
        "    for row, idx in enumerate(indices):\n",
        "        img_name = image_files[idx]\n",
        "        paths = [\n",
        "            os.path.join(folders['image'], img_name),\n",
        "            os.path.join(folders['gt_object'], img_name.replace('.jpg', '.png')),\n",
        "            os.path.join(folders['gt_edge'], img_name.replace('.jpg', '.png')),\n",
        "            os.path.join(folders['gt_instance'], img_name.replace('.jpg', '.png'))\n",
        "        ]\n",
        "        for col, (path, tname) in enumerate(zip(paths, type_names)):\n",
        "            img = Image.open(path)\n",
        "            axes[row, col].imshow(img if col == 0 else img, cmap=None if col == 0 else 'gray')\n",
        "            axes[row, col].set_title(tname)\n",
        "            axes[row, col].axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "show_all_types(train_folders, indices=range(5))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "30qW-zfGgLeL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from timm.models.swin_transformer import swin_tiny_patch4_window7_224\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "try:\n",
        "    import timm\n",
        "except ImportError:\n",
        "    !pip install timm\n",
        "    import timm\n",
        "\n",
        "class SwinEncoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.encoder = swin_tiny_patch4_window7_224(pretrained=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = []\n",
        "        x = self.encoder.patch_embed(x)\n",
        "\n",
        "        x = self.encoder.layers[0](x)\n",
        "        features.append(x.permute(0, 3, 1, 2))\n",
        "\n",
        "        x = self.encoder.layers[1](x)\n",
        "        features.append(x.permute(0, 3, 1, 2))\n",
        "\n",
        "        x = self.encoder.layers[2](x)\n",
        "        features.append(x.permute(0, 3, 1, 2))\n",
        "\n",
        "        x = self.encoder.layers[3](x)\n",
        "        features.append(x.permute(0, 3, 1, 2))\n",
        "\n",
        "        return features\n"
      ],
      "metadata": {
        "id": "hMYgemYPgW4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "class FOM(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels=32):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, 1)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.act = nn.LeakyReLU(0.2)\n",
        "        self.drop = nn.Dropout2d(0.2)\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.bn(x)\n",
        "        x = self.act(x)\n",
        "        x = self.drop(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "JxFzHibwgW7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class FID(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv3x3_1_s1 = nn.Conv2d(in_channels, out_channels, 3, padding=1)\n",
        "        self.bn1_s1 = nn.BatchNorm2d(out_channels)\n",
        "        self.act1_s1 = nn.LeakyReLU(0.2)\n",
        "        self.drop1_s1 = nn.Dropout2d(0.2)\n",
        "\n",
        "        self.conv3x3_1_s2 = nn.Conv2d(in_channels, out_channels, 3, padding=1)\n",
        "        self.bn1_s2 = nn.BatchNorm2d(out_channels)\n",
        "        self.act1_s2 = nn.LeakyReLU(0.2)\n",
        "        self.drop1_s2 = nn.Dropout2d(0.2)\n",
        "\n",
        "        self.fusion_conv = nn.Conv2d(out_channels * 2, out_channels, 1)\n",
        "        self.fusion_bn = nn.BatchNorm2d(out_channels)\n",
        "        self.fusion_act = nn.LeakyReLU(0.2)\n",
        "        self.fusion_drop = nn.Dropout2d(0.2)\n",
        "\n",
        "    def forward(self, S1, S2):\n",
        "        x1 = self.conv3x3_1_s1(S1)\n",
        "        x1 = self.bn1_s1(x1)\n",
        "        x1 = self.act1_s1(x1)\n",
        "        x1 = self.drop1_s1(x1)\n",
        "\n",
        "        x2 = self.conv3x3_1_s2(S2)\n",
        "        x2 = self.bn1_s2(x2)\n",
        "        x2 = self.act1_s2(x2)\n",
        "        x2 = self.drop1_s2(x2)\n",
        "\n",
        "        x2_upsampled = F.interpolate(x2, size=x1.shape[2:], mode='bilinear', align_corners=False)\n",
        "\n",
        "        fused_features = torch.cat([x1, x2_upsampled], dim=1)\n",
        "\n",
        "        output = self.fusion_conv(fused_features)\n",
        "        output = self.fusion_bn(output)\n",
        "        output = self.fusion_act(output)\n",
        "        output = self.fusion_drop(output)\n",
        "\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "9H3K-oOdgW9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class FHIM(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, 3, padding=1)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.act = nn.LeakyReLU(0.2)\n",
        "        self.drop = nn.Dropout2d(0.2)\n",
        "\n",
        "    def forward(self, *features):\n",
        "        target_size = features[0].shape[2:]\n",
        "        upsampled_features = []\n",
        "\n",
        "        for feature in features:\n",
        "            if feature.shape[2:] != target_size:\n",
        "                upsampled_feature = F.interpolate(feature, size=target_size, mode='bilinear', align_corners=False)\n",
        "                upsampled_features.append(upsampled_feature)\n",
        "            else:\n",
        "                upsampled_features.append(feature)\n",
        "\n",
        "        x = torch.cat(upsampled_features, dim=1)\n",
        "\n",
        "        x = self.conv(x)\n",
        "        x = self.bn(x)\n",
        "        x = self.act(x)\n",
        "        x = self.drop(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "5qSYARBZgXAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class BRM(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, in_channels, 3, padding=1)\n",
        "        self.bn = nn.BatchNorm2d(in_channels)\n",
        "        self.act = nn.LeakyReLU(0.2)\n",
        "        self.drop = nn.Dropout2d(0.2)\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.bn(x)\n",
        "        x = self.act(x)\n",
        "        x = self.drop(x)\n",
        "        dilated = F.max_pool2d(x, kernel_size=3, stride=1, padding=1)\n",
        "        eroded = -F.max_pool2d(-x, kernel_size=3, stride=1, padding=1)\n",
        "        feature = dilated - eroded\n",
        "        return feature\n"
      ],
      "metadata": {
        "id": "cyIIZUnQgeqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "class IFBONet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.encoder = SwinEncoder()\n",
        "        self.fom = nn.ModuleList([FOM(96), FOM(192), FOM(384), FOM(768)])\n",
        "        self.fid = FID(32, 32)\n",
        "        self.fhim = FHIM(32 * 3, 32)\n",
        "        self.brm = BRM(32)\n",
        "        self.final = nn.Conv2d(32, 1, 1)\n",
        "        self.edge_final = nn.Conv2d(32, 1, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        feats = self.encoder(x)\n",
        "\n",
        "        c = [self.fom[i](feats[i]) for i in range(4)]\n",
        "\n",
        "        f_fid = self.fid(c[2], c[3])\n",
        "\n",
        "        f_fhim = self.fhim(c[0], c[1], f_fid)\n",
        "\n",
        "        f_brm = self.brm(f_fhim)\n",
        "\n",
        "        mask_raw = self.final(f_brm)\n",
        "        edge_raw = self.edge_final(f_brm)\n",
        "\n",
        "        mask_pred = F.interpolate(mask_raw, size=(224, 224), mode='bilinear', align_corners=False)\n",
        "        edge_pred = F.interpolate(edge_raw, size=(224, 224), mode='bilinear', align_corners=False)\n",
        "\n",
        "        mask_output = torch.sigmoid(mask_pred)\n",
        "        edge_output = torch.sigmoid(edge_pred)\n",
        "\n",
        "        return mask_output, edge_output"
      ],
      "metadata": {
        "id": "lgBSuG-Ogesz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=3, min_delta=0):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.best_loss = None\n",
        "        self.early_stop = False\n",
        "    def __call__(self, val_loss):\n",
        "        if self.best_loss is None or val_loss < self.best_loss - self.min_delta:\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n"
      ],
      "metadata": {
        "id": "EjURwBA4gjA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "def compute_mae(pred, mask):\n",
        "    return torch.abs(pred.sigmoid() - mask).mean().item()\n",
        "\n",
        "def compute_smeasure(pred, mask):\n",
        "    pred = pred.sigmoid()\n",
        "    alpha = 0.5\n",
        "    mean_pred = pred.mean()\n",
        "    mean_mask = mask.mean()\n",
        "    s_obj = 1 - ((mean_pred - mean_mask) ** 2)\n",
        "    return alpha * s_obj.item()\n",
        "\n",
        "def compute_ephi(pred, mask):\n",
        "    pred = pred.sigmoid()\n",
        "    fg = mask * pred\n",
        "    bg = (1 - mask) * (1 - pred)\n",
        "    score = (fg.sum() + bg.sum()) / (mask.numel() + 1e-8)\n",
        "    return score.item()"
      ],
      "metadata": {
        "id": "gDCNKsh9oscG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def loss_fn(pred, mask, edge_pred, edge_gt):\n",
        "    bce_main = F.binary_cross_entropy(pred, mask)\n",
        "    bce_edge = F.binary_cross_entropy(edge_pred, edge_gt)\n",
        "    intersection = (pred * mask).sum(dim=(1, 2, 3))\n",
        "    union = (pred + mask).sum(dim=(1, 2, 3)) - intersection\n",
        "    iou_loss = 1 - (intersection + 1e-6) / (union + 1e-6)\n",
        "    iou_loss = iou_loss.mean()\n",
        "\n",
        "    return 1.0 * bce_main + 0.5 * bce_edge + 1.0 * iou_loss\n",
        "\n"
      ],
      "metadata": {
        "id": "hvA9hSsCovqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = IFBONet().to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "early_stopper = EarlyStopping(patience=10, min_delta=1e-4)\n",
        "\n",
        "num_epochs = 50\n",
        "train_losses, val_losses = [], []\n",
        "train_maes, val_maes = [], []\n",
        "train_salphas, val_salphas = [], []\n",
        "train_fbws, val_fbws = [], []\n",
        "train_ephis, val_ephis = [], []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    epoch_loss = epoch_mae = epoch_salpha = epoch_fbw = epoch_ephi = 0\n",
        "    for img, mask in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
        "        img, mask = img.to(device), mask.to(device)\n",
        "        pred, edge_pred = model(img)\n",
        "\n",
        "        loss = loss_fn(pred, mask, edge_pred, mask)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_mae += compute_mae(pred, mask)\n",
        "        epoch_salpha += compute_smeasure(pred, mask)\n",
        "        epoch_fbw += compute_fbw(pred, mask)\n",
        "        epoch_ephi += compute_ephi(pred, mask)\n",
        "\n",
        "    n_train = len(train_loader)\n",
        "    train_losses.append(epoch_loss / n_train)\n",
        "    train_maes.append(epoch_mae / n_train)\n",
        "    train_salphas.append(epoch_salpha / n_train)\n",
        "    train_ephis.append(epoch_ephi / n_train)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Train Loss: {train_losses[-1]:.4f}, MAE: {train_maes[-1]:.4f}, \"\n",
        "          f\"Sα: {train_salphas[-1]:.4f}, Eφ: {train_ephis[-1]:.4f}\")\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = val_mae = val_salpha = val_fbw = val_ephi = 0\n",
        "    with torch.no_grad():\n",
        "        for img, mask in val_loader:\n",
        "            img, mask = img.to(device), mask.to(device)\n",
        "            pred, edge_pred = model(img)\n",
        "\n",
        "            loss = loss_fn(pred, mask, edge_pred, mask)\n",
        "            val_loss += loss.item()\n",
        "            val_mae += compute_mae(pred, mask)\n",
        "            val_salpha += compute_smeasure(pred, mask)\n",
        "            val_fbw += compute_fbw(pred, mask)\n",
        "            val_ephi += compute_ephi(pred, mask)\n",
        "\n",
        "    n_val = len(val_loader)\n",
        "    val_losses.append(val_loss / n_val)\n",
        "    val_maes.append(val_mae / n_val)\n",
        "    val_salphas.append(val_salpha / n_val)\n",
        "    val_ephis.append(val_ephi / n_val)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Val Loss: {val_losses[-1]:.4f}, MAE: {val_maes[-1]:.4f}, \"\n",
        "          f\"Sα: {val_salphas[-1]:.4f}, Eφ: {val_ephis[-1]:.4f}\")\n",
        "\n",
        "    scheduler.step()\n",
        "    early_stopper(val_losses[-1])\n",
        "    if early_stopper.early_stop:\n",
        "        print(\"Early stopping triggered.\")\n",
        "        break\n"
      ],
      "metadata": {
        "id": "BGpQMrc9gjDc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}