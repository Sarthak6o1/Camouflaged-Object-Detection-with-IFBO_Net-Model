# -*- coding: utf-8 -*-
"""U-Net.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1f-n1Y3G51Ka320T0Z1tTeqXvJHvNiM1k
"""

import torch

print(torch.__version__)
print(torch.cuda.is_available())
if torch.cuda.is_available():
    print(torch.cuda.get_device_name(0))
else:
    print("CUDA not available. Running on CPU.")

from google.colab import drive
drive.mount('/content/drive')

from google.colab import drive
drive.mount('/content/drive')
!unzip "/content/drive/MyDrive/archive.zip" -d /content/

import os
print(os.listdir('/content/COD10K-v3'))

train_path = '/content/COD10K-v3/Train'
test_path = '/content/COD10K-v3/Test'

def get_subfolders(base_path):
    return {
        'image': f'{base_path}/Image',
        'gt_object': f'{base_path}/GT_Object',
        'gt_edge': f'{base_path}/GT_Edge',
        'gt_instance': f'{base_path}/GT_Instance'
    }

train_folders = get_subfolders(train_path)
test_folders = get_subfolders(test_path)

import os

def count_files(folder_dict):
    for key, folder in folder_dict.items():
        print(f"{key}: {len(os.listdir(folder))} files")

print("Train set:")
count_files(train_folders)
print("\nTest set:")
count_files(test_folders)

import os
import torch
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image

class COD10KDataset(Dataset):
    def __init__(self, folders, transform=None, mask_transform=None):
        self.image_paths = sorted(os.listdir(folders['image']))
        self.image_dir = folders['image']
        self.mask_dir = folders['gt_object']
        self.transform = transform
        self.mask_transform = mask_transform

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        image_name = self.image_paths[idx]
        img_path = os.path.join(self.image_dir, image_name)
        mask_path = os.path.join(self.mask_dir, image_name.replace('.jpg', '.png'))

        image = Image.open(img_path).convert('RGB')
        mask = Image.open(mask_path).convert('L')

        if self.transform:
            image = self.transform(image)
        if self.mask_transform:
            mask = self.mask_transform(mask)

        return image, mask

from torch.utils.data import random_split

transform = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.ToTensor()
])

mask_transform = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.ToTensor()
])

# Create full training dataset
train_dataset = COD10KDataset(folders=train_folders, transform=transform, mask_transform=mask_transform)
test_dataset = COD10KDataset(folders=test_folders, transform=transform, mask_transform=mask_transform)

# Split into train and validation
train_size = int(0.8 * len(train_dataset))
val_size = len(train_dataset) - train_size
train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])

# Create dataloaders
train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)  # No shuffle for validation
test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)

num_train = len(train_dataset)
num_val = len(val_dataset)
num_test = len(test_dataset)

print(f"Number of training samples: {num_train}")
print(f"Number of validation samples: {num_val}")
print(f"Number of test samples: {num_test}")

images, masks = next(iter(train_loader))

print("Image batch shape:", images.shape)
print("Mask batch shape:", masks.shape)

import matplotlib.pyplot as plt
from PIL import Image
import os

def show_all_types(folders, indices):
    n = len(indices)
    fig, axes = plt.subplots(n, 4, figsize=(12, 5))
    type_names = ['Image', 'GT_Object', 'GT_Edge', 'GT_Instance']
    image_files = sorted(os.listdir(folders['image']))
    for row, idx in enumerate(indices):
        img_name = image_files[idx]
        paths = [
            os.path.join(folders['image'], img_name),
            os.path.join(folders['gt_object'], img_name.replace('.jpg', '.png')),
            os.path.join(folders['gt_edge'], img_name.replace('.jpg', '.png')),
            os.path.join(folders['gt_instance'], img_name.replace('.jpg', '.png'))
        ]
        for col, (path, tname) in enumerate(zip(paths, type_names)):
            img = Image.open(path)
            axes[row, col].imshow(img if col == 0 else img, cmap=None if col == 0 else 'gray')
            axes[row, col].set_title(tname)
            axes[row, col].axis('off')
    plt.tight_layout()
    plt.show()

show_all_types(train_folders, indices=range(5))

import torch
import torch.nn as nn
import torchvision.transforms.functional as TF

class DoubleConv(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(DoubleConv, self).__init__()
        self.conv = nn.Sequential(
            nn.Conv2d(in_channels, out_channels, 3, 1, 1, bias=False),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
        )

    def forward(self, x):
        return self.conv(x)

class UNET(nn.Module):
    def __init__(
            self, in_channels=3, out_channels=1, features=[64, 128, 256, 512],
    ):
        super(UNET, self).__init__()
        self.ups = nn.ModuleList()
        self.downs = nn.ModuleList()
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)

        # Down part of UNET
        for feature in features:
            self.downs.append(DoubleConv(in_channels, feature))
            in_channels = feature

        # Up part of UNET
        for feature in reversed(features):
            self.ups.append(
                nn.ConvTranspose2d(
                    feature*2, feature, kernel_size=2, stride=2,
                )
            )
            self.ups.append(DoubleConv(feature*2, feature))

        self.bottleneck = DoubleConv(features[-1], features[-1]*2)
        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)

    def forward(self, x):
        skip_connections = []

        for down in self.downs:
            x = down(x)
            skip_connections.append(x)
            x = self.pool(x)

        x = self.bottleneck(x)
        skip_connections = skip_connections[::-1]

        for idx in range(0, len(self.ups), 2):
            x = self.ups[idx](x)
            skip_connection = skip_connections[idx//2]

            if x.shape != skip_connection.shape:
                x = TF.resize(x, size=skip_connection.shape[2:])

            concat_skip = torch.cat((skip_connection, x), dim=1)
            x = self.ups[idx+1](concat_skip)

        return self.final_conv(x)

def test():
    x = torch.randn((3, 1, 161, 161))
    model = UNET(in_channels=1, out_channels=1)
    preds = model(x)
    assert preds.shape == x.shape

if __name__ == "__main__":
    test()

import torch
import torch.nn as nn
import torch.optim as optim
from tqdm import tqdm
import matplotlib.pyplot as plt

# 1. Loss and Metrics
class DiceBCELoss(nn.Module):
    def __init__(self, smooth=1e-6):
        super(DiceBCELoss, self).__init__()
        self.smooth = smooth

    def forward(self, inputs, targets):
        inputs = torch.sigmoid(inputs)
        inputs = inputs.view(-1)
        targets = targets.view(-1)

        intersection = (inputs * targets).sum()
        dice_loss = 1 - (2.*intersection + self.smooth)/(inputs.sum() + targets.sum() + self.smooth)
        BCE = nn.functional.binary_cross_entropy(inputs, targets, reduction='mean')
        return BCE + dice_loss

def calculate_iou(preds, targets):
    preds = torch.sigmoid(preds) > 0.5
    targets = targets > 0.5
    intersection = (preds & targets).float().sum()
    union = (preds | targets).float().sum()
    return (intersection + 1e-6) / (union + 1e-6)

# 2. Training Function
def train_unet(
    model,
    train_loader,
    val_loader,
    epochs=40,
    learning_rate=1e-4,
    device="cuda" if torch.cuda.is_available() else "cpu"
):
    model.to(device)
    criterion = DiceBCELoss()
    optimizer = optim.Adam(model.parameters(), lr=learning_rate)

    best_iou = 0.0
    history = {
        'train_loss': [],
        'val_loss': [],
        'val_iou': []
    }

    for epoch in range(epochs):
        model.train()
        train_loss = 0.0

        # Training loop
        for images, masks in tqdm(train_loader, desc=f"Epoch {epoch+1}/{epochs}"):
            images = images.to(device)
            masks = masks.to(device)

            # Forward pass
            outputs = model(images)
            loss = criterion(outputs, masks)

            # Backward pass
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            train_loss += loss.item() * images.size(0)

        # Validation
        val_loss, val_iou = validate(model, val_loader, criterion, device)

        # Update history
        train_loss = train_loss / len(train_loader.dataset)
        history['train_loss'].append(train_loss)
        history['val_loss'].append(val_loss)
        history['val_iou'].append(val_iou)

        # Print progress
        print(f"\nTrain Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val IoU: {val_iou:.4f}")

        # Save best model
        if val_iou > best_iou:
            best_iou = val_iou
            torch.save(model.state_dict(), 'best_unet.pth')

    print(f"\nTraining complete. Best IoU: {best_iou:.4f}")
    return history

# 3. Validation Function
def validate(model, val_loader, criterion, device):
    model.eval()
    val_loss = 0.0
    val_iou = 0.0

    with torch.no_grad():
        for images, masks in val_loader:
            images = images.to(device)
            masks = masks.to(device)

            outputs = model(images)
            loss = criterion(outputs, masks)

            val_loss += loss.item() * images.size(0)
            val_iou += calculate_iou(outputs, masks).item() * images.size(0)

    return val_loss / len(val_loader.dataset), val_iou / len(val_loader.dataset)

# 4. Usage Example
if __name__ == "__main__":
    # Initialize model
    model = UNET(in_channels=3, out_channels=1)

    # Train the model
    history = train_unet(
        model=model,
        train_loader=train_loader,  # Use your DataLoader
        val_loader=val_loader,      # Use your DataLoader
        epochs=40,
        learning_rate=1e-4
    )

    # Plot training history
    plt.figure(figsize=(12, 5))
    plt.subplot(1, 2, 1)
    plt.plot(history['train_loss'], label='Train Loss')
    plt.plot(history['val_loss'], label='Val Loss')
    plt.title('Training and Validation Loss')
    plt.legend()

    plt.subplot(1, 2, 2)
    plt.plot(history['val_iou'], label='Validation IoU', color='green')
    plt.title('Validation IoU Score')
    plt.legend()
    plt.show()
